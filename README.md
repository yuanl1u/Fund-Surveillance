# fund-surveillance
### 基金实时监控小程序 （Scrapy爬虫）

#### 本小程序为了解决：  
1、支付宝基金仅在手机端支持，如需关注自己购买的基金涨跌情况需经历繁琐的打开支付宝等操作。  
2、各种基金网站及支付宝基金应用内无法提供我需要的整体资讯（包含大盘涨跌、关注基金涨跌和板块涨跌情况）  
![enter image description here](https://github.com/yuanl1u/fund-surveillance/blob/master/fund_pic.png?raw=true)

#### 程序主要思路：
1、利用“天天基金网”和“新浪”的股市数据接口抓取实时数据。
天天基金网**基金**数据：http://fundgz.1234567.com.cn/js/000001.js
天天基金网**板块**数据：http://86.push2.eastmoney.com/api/qt/clist/get?cb=jQuery112408858469234434023_1598845677208&pn=1&pz=10&po=1&np=1&ut=bd1d9ddb04089700cf9c27f6f7426281&fltt=2&invt=2&fid=f3&fs=m:90+t:2&fields=f1,f2,f3,f4,f5,f6,f7,f8,f9,f10,f12,f13,f14,f15,f16,f17,f18,f20,f21,f23,f24,f25,f22,f11,f62,f128,f136,f115,f152,f133,f104,f105&_=1598845677209
新浪网基金数据（用于查大盘情况）：http://hq.sinajs.cn/list=s_sh000001

两个接口只要修改最后的基金代码即可(000001/s_sh000001)

* 天天基金网接口返回的数据：

> jsonpgz({"**fundcode**":"000001","**name**":"鍗庡鎴愰暱娣峰悎","jzrq":"2020-09-03","dwjz":"1.4370","**gsz**":"1.4332","**gszzl**":"-0.27","gztime":"2020-09-04
> 15:00"});

取中间的json部分进行解析，各个字段分别代表不同含义：
**name：基金名称
fundcode：基金代码
gsz：价格
gszzl：当前涨跌百分比**

* 天天基金网板块接口返回的数据:

> jQuery112408858469234434023_1598845677208({"rc":0,"rt":6,"svr":181734937,"lt":1,"full":1,"data":{"total":61,"diff":[{"f1":2,"f2":4483.85,**"f3":2.47**,"f4":107.99,"f5":5838209,"f6":5363371520.0,"f7":4.43,"f8":1.08,"f9":131.64,"f10":1.41,"f11":0.16,"f12":"BK0420","f13":90,**"f14":"民航机场"**,"f15":4484.66,"f16":4290.88,"f17":4319.13,"f18":4375.86,"f20":591966624000,"f21":406907056000,"f22":0.03,"f23":"-","f24":12.68,"f25":-2.58,"f62":208226688.0,"f104":12,"f105":1,"f115":"-",**"f128":"吉祥航空"**...

依然为json数据，内包含字段：
**f3:涨跌百分比
f14:涨跌名称
f128:代表股票**

* 新浪网接口返回的数据：

> var hq_str_s_sh000001="**上证指数,3355.3666,-29.6140,-0.87**,2216365,30817966";

新浪网接口的数据更简单一些，各个字段用逗号隔开，
分别代表：**名称，点数，涨跌点数，涨跌百分比...**

2、将抓取到的各种数据利用Scrapy的item机制保存在各个item中，并且在piplines中输出到屏幕上，并且在pipelines.py中输出到cmd窗口。
期间主要解决问题：
* 对齐 
	网上找了个现成的函数rpad然后修改一下想对齐的几个输出就行了...
* 颜色
	调用colorama包，可以方便地修改cmd输出的字体前景色、背景色等。
	使用方法也非常便捷：哪里需要颜色就相应的在输出前加Fore.COLOR。

> `temp_list[1] = (Fore.GREEN + temp_list[1] + "%" + Style.RESET_ALL)
> 
最后要加上Style.RESET_ALL不然下一行也跟着变颜色。

3、接口一次只能爬取一只基金的信息，因此把想要抓取的基金代码放在cgf.csv文件中（应为cfg，手误）：

> 007028,688.19 
> 161005,460.16
>  005609,943.56
>  163115,762.56
>  000083,449.81
>  161125,500.00
>  003634,500.00

文件内容如上，格式为[代码],[持有金额]
持有金额部分本是打算可以计算每日盈亏的，后因为各种原因放弃掉这个功能。
spiders.py的逻辑是先读取csv文件，修改接口地址，然后爬取修改过后的地址。

4、后期设计了一个 dataMenu.py，可以不用每次打开csv文件手动修改想要监控的基金代码。
目录写的烂而冗长，不赘述。

5、主程序 main.py 每30秒运行一次spiders.py中的四个爬虫（关注基金、股市指数、领涨板块、领跌板块）
    
    


